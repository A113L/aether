**Hashcat Rule Performance Benchmark**

[![concentrator-MT-50000-statistical.png](https://i.postimg.cc/3xQkyzmg/concentrator-MT-50000-statistical.png)](https://postimg.cc/56p4T7P0)

*"Just as the Michelson-Morley experiment of 1887 sought to measure the fundamental constants of the universe, this tool measures the fundamental performance characteristics of hashcat rules with scientific precision."*

**Overview**

A high-precision benchmarking tool that empirically measures hashcat rule performance using OpenCL acceleration. Inspired by the rigorous experimental methodology of the Michelson-Morley experiment, this tool provides statistically significant performance data to optimize password cracking rule sets.

**Scientific Approach**

Michelson-Morley Inspiration (1887)

Just as Michelson and Morley sought to measure the luminiferous ether with unprecedented precision, this tool measures rule performance with:

- Interferometric Precision: Multiple test runs with statistical outlier removal
- Null Hypothesis Testing: Rules must demonstrate consistent performance across identical conditions
- Control Variables: Identical dictionary sets for reliable comparisons
- Measurement Accuracy: Coefficient of Variation (CV) calculations to quantify uncertainty

**Key Metrics Measured**

- Execution Time (Î¼s): Mean, median with outlier rejection
- Operations/Second: Throughput calculation
- Coefficient of Variation: Measurement stability (â‰¤10% = excellent)
- Statistical Confidence: Multiple runs with 2-sigma outlier removal

**Features**

- Colorized Terminal Output - Instant visual performance feedback
- Statistical Robustness - Multiple test runs with outlier detection
- OpenCL GPU Acceleration - Direct kernel execution for accurate timing
- Consistency Validation - Michelson-Morley inspired identical-condition testing
- Performance Ranking - Rules sorted from fastest to slowest
- Smart Optimization - Create optimized rule sets based on empirical data

**Installation**

```
# Clone repository
wget https://github.com/A113L/aether/raw/refs/heads/main/aether.py

# Install dependencies
pip install pyopencl numpy

# Verify OpenCL support
python -c "import pyopencl as cl; print([d.name for d in cl.get_platforms()[0].get_devices()])"
```
```Usage Examples```

*Basic Performance Testing*
```
# Test single rule file with dictionary
python3 rule_benchmark.py -r best64.rule -d rockyou.txt
```
*Scientific-Grade Accuracy*
```
# High-precision testing (Michelson-Morley approach)
python3 rule_benchmark.py \
    -r best64.rule combinator.rule \
    -d rockyou.txt \
    --test-runs 10 \
    --iterations 100 \
    --identical-dicts \
    --output ./scientific_results
```

*Rule Set Optimization*
```
# Create optimized rule set from multiple files
python3 rule_benchmark.py \
    -r ./rules/ ./more_rules/ \
    -d ./dictionaries/ \
    --optimize \
    --max-rules 500 \
    --max-time 30.0
```

*Consistency Validation*
```
# Test rule consistency across identical conditions
python3 rule_benchmark.py \
    -r best64.rule \
    -d rockyou.txt rockyou.txt \  # Same dictionary twice
    --identical-dicts
```

**Output Interpretation**

*Color-Coded Performance*

ðŸŸ¢ Green: Excellent performance (< 1ms, CV â‰¤ 10%)

ðŸŸ¡ Yellow: Good performance (1-10ms, CV â‰¤ 20%)

ðŸ”´ Red: Poor performance (> 10ms, CV > 20%)

**Statistical Metrics**

```
{
  "mean_time": 0.000456,      # Average execution time (seconds)
  "median_time": 0.000443,    # Median (outlier resistant)
  "std_time": 0.000023,       # Standard deviation
  "cv_percent": 5.04,         # Coefficient of Variation (%)
  "operations_per_sec": 2,193,877  # Throughput
}
```

**Experimental Methodology**

```
1. Control Conditions

# Identical dictionary sets for reliable comparisons
self.setup_test_data(args.dict, use_identical_sets=True)
2. Multiple Measurement Runs

# 5 test runs per rule with outlier removal
performance_data = self.test_single_rule_performance(rule, test_runs=5)
3. Statistical Processing

# 2-sigma outlier rejection (95% confidence)
filtered_times = [t for t in execution_times if abs(t - mean) <= 2 * std]
4. Consistency Validation

# Michelson-Morley inspired consistency checking
consistency = self.validate_rule_consistency(
    performance_run1, 
    performance_run2, 
    threshold_percent=15.0  # â‰¤15% difference allowed
)
```

**Sample Results**

Performance Ranking

```
# Rules sorted by performance (fastest first)
# Generated by RulePerformanceTester  
# Total rules: 64
# Test date: 2024-01-15 14:30:22

l # 0.000123s 813,008 ops/sec 4.2% CV
u # 0.000145s 689,655 ops/sec 5.1% CV
c # 0.000167s 598,802 ops/sec 6.3% CV
$1 # 0.000189s 529,100 ops/sec 7.8% CV
^! # 0.000234s 427,350 ops/sec 12.1% CV
```

**Optimization Report**

```
{
  "optimization_parameters": {
    "max_rules": 500,
    "max_total_time": 30.0,
    "actual_rules_selected": 347,
    "actual_total_time": 29.876
  }
}
```

**Advanced Configuration**

Accuracy vs Speed Trade-offs

```
# Research Grade (Highest Accuracy)
python3 rule_benchmark.py --test-runs 10 --iterations 200 --max-words 2000

# Production Grade (Balanced)
python3 rule_benchmark.py --test-runs 5 --iterations 100 --max-words 1000

# Development Grade (Fast)
python3 rule_benchmark.py --test-runs 3 --iterations 50 --max-words 500
```

**OpenCL Device Selection**

```
# Manual device selection for specific hardware
tester = RulePerformanceTester(platform_index=0, device_index=0)
```

```Use Cases```

- Hash Cracking Optimization
- Rule Set Tuning: Identify and remove slow-performing rules
- Strategy Planning: Estimate attack duration for rule sets

**Resource Allocation: Optimize GPU utilization**

**Academic Research**

- Algorithm Analysis: Study rule complexity characteristics
- Performance Modeling: Build predictive models for rule execution
- Hardware Benchmarking: Compare GPU performance across devices

**Security Assessment**

- Defense Planning: Understand attacker capabilities
- Policy Development: Inform password policy decisions
- Risk Analysis: Quantify rule-based attack effectiveness

**Statistical Methods**

- Outlier Detection: 2-sigma rule (95% confidence interval)
- Central Tendency: Mean and median calculations
- Variability Measurement: Coefficient of Variation (CV)
- Consistency Validation: Threshold-based performance matching

**License**

MIT License - See LICENSE file for details

**References**

- Michelson, A. A., & Morley, E. W. (1887). On the Relative Motion of the Earth and the Luminiferous Ether
- Hashcat Project - Rule-based password recovery
- OpenCL Specification - Heterogeneous computing

**Credits**

- Michelson & Morley (1887) - For inspiring rigorous experimental methodology
- Hashcat Community - For rule specifications and testing methodologies
- OpenCL Working Group - For heterogeneous computing standards

**Website**

https://hcrt.pages.dev/aether.static_workflow

"We measure what is measurable, and make measurable what cannot be measured." - Galileo Galilei
